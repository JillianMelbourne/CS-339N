{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXOMrfqxKOx"
      },
      "source": [
        "# PyTorch Primer\n",
        "\n",
        "We'll use Python and [PyTorch](https://pytorch.org/) for the labs in this course. This lab is to help you get up to speed. It will introduce:\n",
        "- **Tensors**: PyTorch's equivalent of NumPy arrays, but with more bells and whistles for running on GPUs and supporting automatic differentiation.\n",
        "- **Broadcasting and Fancy Indexing**: If you're coming from Matlab or NumPy, you probably know that you can avoid costly for-loops by broadcasting computation over dimensions of an array (here, tensor) and using fancy indexing tricks.\n",
        "- **Distributions**: PyTorch has an excellent library of distributions for sampling, evaluating log probabilities, and much more.\n",
        "\n",
        "We'll introduce these concepts in the context of the Poisson mixture model from class (c.f. [Probabilistic Modeling](../lectures/02_probabilistic_modeling.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0UKrlop6xKOz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.distributions as dist\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7jKm4UGxKOz"
      },
      "source": [
        "## 1. Constructing Tensors\n",
        "\n",
        "Tensors are PyTorch's equivalent of NumPy arrays. The PyTorch documentation already has a [great tutorial](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) on tensors. Rather than recreate the wheel, please start by reading that.\n",
        "\n",
        "Once you've read through that, try using torch functions like `arange`, `reshape`, etc. to construct the following tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xxAUJ83xKO0"
      },
      "source": [
        "### Problem 1.1\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([[0, 1, 2],\n",
        "        [3, 4, 5],\n",
        "        [6, 7, 8]])\n",
        "```\n",
        "\n",
        "_Note: For this problems and the ones below, don't literally construct the tensor from the specified list. Use torch functions._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fRk5rMfxKO0",
        "outputId": "dfe0ae40-bd0d-40da-b0c0-b37c3d434b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: \n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "shape = (3, 3)\n",
        "# .arange provides a 1D tensor with values evenly distributed from 0 to no.prod(shape)- 1 which is the product of the shape (3 * 3)\n",
        "# .reshape reshapes the tensor to the original (3, 3) shape\n",
        "tensor = torch.arange(np.prod(shape)).reshape(shape)\n",
        "print(f\"Tensor: \\n {tensor}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAJb2b7MxKO0"
      },
      "source": [
        "### Problem 1.2\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([[0, 3, 6],\n",
        "        [1, 4, 7],\n",
        "        [2, 5, 8]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDw7pBfPxKO0",
        "outputId": "d6f86114-c604-4d8d-beaf-5dc15898d2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 3, 6],\n",
            "        [1, 4, 7],\n",
            "        [2, 5, 8]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "print(tensor.T) #transpose the tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIDSKMtuxKO0"
      },
      "source": [
        "### Problem 1.3\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
        "```\n",
        "\n",
        "_Note: Here the sequence is repeated 3 times. Does your code support arbitrary numbers of repeats?_\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHYQGQFVxKO0",
        "outputId": "07d8ee4c-5017-48f4-8391-07b78957eeae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "tensor = tensor.flatten()[:5] # flatten the first five values of the tensor\n",
        "tensor = tensor.repeat(1, 3) # repeat the tensor three times in the row direction\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk5HkyVnxKO1"
      },
      "source": [
        "### Problem 1.4\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([[0, 1, 2, 3, 4],\n",
        "        [0, 1, 2, 3, 4],\n",
        "        [0, 1, 2, 3, 4]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBInBYaUxKO1",
        "outputId": "f8b4cc24-808a-40d2-f8f0-fbcddea32e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4],\n",
            "        [0, 1, 2, 3, 4],\n",
            "        [0, 1, 2, 3, 4]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "shape = (3,5)\n",
        "tensor = tensor.reshape(shape)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PvxJkhGxKO1"
      },
      "source": [
        "### Problem 1.5\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([[ 1., -2.,  0.,  0.],\n",
        "        [-2.,  1., -2.,  0.],\n",
        "        [ 0., -2.,  1., -2.],\n",
        "        [ 0.,  0., -2.,  1.]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGtPvdZlxKO1",
        "outputId": "233917c5-1a03-4999-d86e-46c3aa926432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1., -2.,  0.,  0.],\n",
            "        [-2.,  1., -2.,  0.],\n",
            "        [ 0., -2.,  1., -2.],\n",
            "        [ 0.,  0., -2.,  1.]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Create 4x4 tensor full of zeros\n",
        "shape = (4,4)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "# Fill diagonal with 1.\n",
        "diag_tensor = zeros_tensor.fill_diagonal_(1.)\n",
        "\n",
        "# Create Super- and Sub- diagnonal tensors filled with -.2\n",
        "shape = (3,)\n",
        "neg_2 = torch.full(shape, -2.)  # Fill with -2\n",
        "super_diag = torch.diag_embed(tensor, offset = 1)\n",
        "sub_diag = torch.diag_embed(tensor, offset = -1)\n",
        "\n",
        "#Add tensors together\n",
        "tensor = diag_tensor + super_diag + sub_diag\n",
        "print(tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IwhGW5OxKO1"
      },
      "source": [
        "### Problem 1.6\n",
        "\n",
        "Construct the following tensor:\n",
        "\n",
        "```\n",
        "tensor([[[[0, 1, 2]]]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt8VchxvxKO1",
        "outputId": "baa8c6c7-eefa-44a5-97c3-c6c6e171a339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0, 1, 2]]]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "tensor = torch.arange(3).reshape(1, 1, 1, 3)  # Automatically generate [0,1,2] and reshape\n",
        "\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeIg4WNExKO1"
      },
      "source": [
        "## 2. Broadcasting and Fancy Indexing\n",
        "\n",
        "Your life will be much easier and your code will be much faster once you get the hang of broadcasting and indexing. Start by reading the  [PyTorch documentation](https://pytorch.org/docs/stable/notes/broadcasting.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KPtXGPfxKO1"
      },
      "source": [
        "### Problem 2.1\n",
        "\n",
        "Construct a tensor `X` where `X[i,j] = i + j` by broadcasting a sum of two 1-dimensional tensors.\n",
        "\n",
        "For example, broadcast a sum to construct the following tensor,\n",
        "\n",
        "```\n",
        "tensor([[0, 1, 2],\n",
        "        [1, 2, 3],\n",
        "        [2, 3, 4],\n",
        "        [3, 4, 5]])\n",
        "```        \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbOQjNUBxKO1",
        "outputId": "d095a92b-634b-4753-b40c-41d329515122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [1, 2, 3],\n",
              "        [2, 3, 4],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "i_shape = (1, 3)\n",
        "j_shape = (4,1)\n",
        "i = torch.arange(3).reshape(i_shape)\n",
        "j = torch.arange(4).reshape(j_shape)\n",
        "X = i + j\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oih3LzDPxKO1"
      },
      "source": [
        "### Problem 2.2\n",
        "\n",
        "Compute a distance matrix `D` where `D[i,j]` is the Euclidean distance between `X[i]` and `X[j]`, with\n",
        "\n",
        "```\n",
        "X = torch.arange(10, dtype=float).reshape(5, 2)\n",
        "```\n",
        "\n",
        "Your answer should be,\n",
        "\n",
        "```\n",
        "tensor([[ 0.0000,  2.8284,  5.6569,  8.4853, 11.3137],\n",
        "        [ 2.8284,  0.0000,  2.8284,  5.6569,  8.4853],\n",
        "        [ 5.6569,  2.8284,  0.0000,  2.8284,  5.6569],\n",
        "        [ 8.4853,  5.6569,  2.8284,  0.0000,  2.8284],\n",
        "        [11.3137,  8.4853,  5.6569,  2.8284,  0.0000]])\n",
        "```        \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBjjJwPLxKO2",
        "outputId": "87b14d24-f410-4a2f-f80a-b88d98192144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  2.8284,  5.6569,  8.4853, 11.3137],\n",
            "        [ 2.8284,  0.0000,  2.8284,  5.6569,  8.4853],\n",
            "        [ 5.6569,  2.8284,  0.0000,  2.8284,  5.6569],\n",
            "        [ 8.4853,  5.6569,  2.8284,  0.0000,  2.8284],\n",
            "        [11.3137,  8.4853,  5.6569,  2.8284,  0.0000]], dtype=torch.float64)\n",
            "tensor([[0., 1.],\n",
            "        [2., 3.],\n",
            "        [4., 5.],\n",
            "        [6., 7.],\n",
            "        [8., 9.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "X = torch.arange(10, dtype=float).reshape(5, 2)\n",
        "# YOUR CODE HERE\n",
        "D = torch.cdist(X, X, p=2)  # p=2 specifies Euclidean distance\n",
        "print(D)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6irspaFxKO2"
      },
      "source": [
        "### Problem 2.3\n",
        "\n",
        "Extract the submatrix of rows `[2,3]` and columns `[0,1,4]` of the tensor,\n",
        "```\n",
        "A = torch.arange(25).reshape(5, 5)\n",
        "```\n",
        "\n",
        "Your answer should be,\n",
        "```\n",
        "tensor([[10, 11, 14],\n",
        "        [15, 16, 19]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5habLSFzxKO2",
        "outputId": "d5ae5cf3-a7cc-4446-c6e6-6cd527606af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19],\n",
            "        [20, 21, 22, 23, 24]]) \n",
            "\n",
            "tensor([[10, 11, 14],\n",
            "        [15, 16, 19]])\n"
          ]
        }
      ],
      "source": [
        "A = torch.arange(25).reshape(5, 5)\n",
        "# YOUR CODE HERE\n",
        "submatrix = A[[2, 3],:][:,[0, 1, 4]]\n",
        "print(f\"{A} \\n\")\n",
        "print(submatrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8QOHL4GxKO2"
      },
      "source": [
        "### Problem 2.4\n",
        "\n",
        "Create a binary mask matrix `M` of the same shape as `A` where `M[i,j]` is True if and only if `A[i,j]` is divisible by 7. Let\n",
        "\n",
        "```\n",
        "A = torch.arange(25).reshape(5, 5)\n",
        "```\n",
        "\n",
        "Your answer should be\n",
        "\n",
        "```\n",
        "tensor([[ True, False, False, False, False],\n",
        "        [False, False,  True, False, False],\n",
        "        [False, False, False, False,  True],\n",
        "        [False, False, False, False, False],\n",
        "        [False,  True, False, False, False]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldt2jqHzxKO3",
        "outputId": "9498805b-0e1b-49d0-9c68-7623a8887775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True, False, False, False, False],\n",
            "        [False, False,  True, False, False],\n",
            "        [False, False, False, False,  True],\n",
            "        [False, False, False, False, False],\n",
            "        [False,  True, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "A = torch.arange(25).reshape(5, 5)\n",
        "# YOUR CODE HERE\n",
        "M = (A % 7 == 0)\n",
        "print(M)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX_D6H2JxKO3"
      },
      "source": [
        "### Problem 2.5\n",
        "\n",
        "Add one to the entries in `A` that are divisible by 7. After updating in place, `A` should be,\n",
        "\n",
        "```\n",
        "tensor([[ 1,  1,  2,  3,  4],\n",
        "        [ 5,  6,  8,  8,  9],\n",
        "        [10, 11, 12, 13, 15],\n",
        "        [15, 16, 17, 18, 19],\n",
        "        [20, 22, 22, 23, 24]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRwa0lYhxKO3",
        "outputId": "79536e73-3e53-4c4e-f1c3-9d638ce788b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  1,  2,  3,  4],\n",
            "        [ 5,  6,  8,  8,  9],\n",
            "        [10, 11, 12, 13, 15],\n",
            "        [15, 16, 17, 18, 19],\n",
            "        [20, 22, 22, 23, 24]])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "A[M] += 1\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jU8m5xixKO3"
      },
      "source": [
        "## 3. Distributions\n",
        "\n",
        "PyTorch has an excellent library of distributions in `torch.distributions`. Read the docs [here](https://pytorch.org/docs/stable/distributions.html).\n",
        "\n",
        "We will use these distribution objects to construct and fit a Poisson mixture model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp6ry921xKO3"
      },
      "source": [
        "### Problem 3.1\n",
        "\n",
        "Draw 50 samples from a Poisson distribution with rate 10.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9_j2gfXxKO3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "m = dist.Poisson(rate = torch.tensor([10.0]))\n",
        "samples = m.sample(sample_shape=torch.Size([50]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflSMOHuxKO3"
      },
      "source": [
        "### Problem 3.2\n",
        "\n",
        "One of the awesome thing about PyTorch distributions is that they support broadcasting too.\n",
        "\n",
        "Construct a matrix `P` where `P[i,j]` equals $\\mathrm{Pois}(x=j; \\lambda=i)$ for $i=0,\\ldots,4$ and $j=0,\\ldots,4$.\n",
        "\n",
        "Your answer should be,\n",
        "```\n",
        "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "        [0.3679, 0.3679, 0.1839, 0.0613, 0.0153],\n",
        "        [0.1353, 0.2707, 0.2707, 0.1804, 0.0902],\n",
        "        [0.0498, 0.1494, 0.2240, 0.2240, 0.1680],\n",
        "        [0.0183, 0.0733, 0.1465, 0.1954, 0.1954]])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtZZ9kjbxKO3",
        "outputId": "d914f0fa-a679-411d-9e68-21cc2286fab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3679, 0.3679, 0.1839, 0.0613, 0.0153],\n",
            "        [0.1353, 0.2707, 0.2707, 0.1804, 0.0902],\n",
            "        [0.0498, 0.1494, 0.2240, 0.2240, 0.1680],\n",
            "        [0.0183, 0.0733, 0.1465, 0.1954, 0.1954]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.]])\n",
            "tensor([0., 1., 2., 3., 4.])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "rate = torch.arange(5).float().unsqueeze(1)\n",
        "x = torch.arange(5).float()\n",
        "m = dist.Poisson(rate = rate)\n",
        "\n",
        "# Create a Poisson distribution with broadcasting\n",
        "poisson_dist = dist.Poisson(rate = rate)\n",
        "\n",
        "# Compute probabilities: P[i, j] = Poisson(x=j | lambda=i)\n",
        "P = poisson_dist.log_prob(x).exp()\n",
        "print(P)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W22RwL1xKO3"
      },
      "source": [
        "### Problem 3.3\n",
        "\n",
        "Evaluate the log probability of the points `[1.5, 3., 4.2]` under a gamma distribution with shape (aka concentration) 2.0 and inverse scale (aka rate) 1.5.\n",
        "\n",
        "Your answer should be,\n",
        "\n",
        "```\n",
        "tensor([-1.0336, -2.5905, -4.0540])\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1u8xzFI0xKO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a4d84c-0473-4b18-abad-b325030556a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.0336, -2.5905, -4.0540])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "x = torch.tensor([1.5, 3., 4.2])\n",
        "gamma_dist = dist.Gamma(concentration = 2.0, rate = 1.5)\n",
        "log_prob = gamma_dist.log_prob(x)\n",
        "print(log_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABWvSDFtxKO4"
      },
      "source": [
        "### Problem 3.4\n",
        "\n",
        "Draw 1000 samples from a Poisson mixture model,\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "p(x) &= \\frac{1}{2} \\mathrm{Pois}(10.0) + \\frac{1}{2} \\mathrm{Pois}(2.0)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Use `matplotlib.pyplot.hist` to plot a normalized histogram of the samples.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nfKpE3t1xKO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0bf2db-dc2f-4d31-9ef8-384679339233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10.,  9., 12.,  8.,  8., 10.,  9.,  8.,  8., 11., 12.,  7., 11., 12.,\n",
            "         7.,  8., 16.,  8., 11., 12.,  8.,  7., 13., 10.,  9., 14., 15.,  5.,\n",
            "        13.,  8., 12.,  7., 12., 14.,  8., 14., 17.,  9.,  9., 13., 11.,  8.,\n",
            "        12., 10.,  7.,  6.,  8., 11., 11.,  9., 12.,  9., 10.,  9., 13.,  7.,\n",
            "        22., 12., 11.,  8.,  8.,  4., 10.,  8., 13.,  7., 13.,  3., 16., 13.,\n",
            "         7.,  8., 12.,  6.,  8., 11.,  9., 14.,  8., 10.,  8., 15., 13., 15.,\n",
            "        13., 11., 18.,  6., 12., 13., 10.,  8., 16.,  9.,  8., 12.,  8.,  8.,\n",
            "        11.,  9., 10., 10., 10.,  7., 15., 15.,  6., 12.,  8., 13.,  9., 13.,\n",
            "        11.,  7.,  9., 11.,  9.,  9.,  9., 10., 11.,  6., 13., 10.,  5.,  7.,\n",
            "         6.,  9., 14., 11., 15.,  7., 11.,  7.,  8.,  8.,  8., 13.,  6.,  5.,\n",
            "        19., 12.,  7.,  5., 17.,  8.,  6., 10., 13., 11., 10.,  5., 10., 12.,\n",
            "         6., 14., 10., 10., 12.,  8., 12., 16.,  9.,  8.,  8., 14., 13., 13.,\n",
            "        16., 10., 11., 14., 13.,  9.,  9., 13., 12., 10., 14.,  5.,  9.,  9.,\n",
            "         5.,  9.,  8.,  9., 12., 13.,  6.,  8.,  9.,  8., 13., 14.,  9., 12.,\n",
            "         8.,  8.,  9., 11.,  8.,  7.,  8., 14.,  6.,  9.,  9., 14.,  5., 13.,\n",
            "        13., 21.,  5., 10.,  6., 10.,  6.,  6.,  9., 13., 11.,  8.,  7., 12.,\n",
            "        10., 10., 13.,  5., 11., 12.,  4.,  5., 15., 14.,  7.,  6.,  9.,  7.,\n",
            "        17., 13., 13., 10., 11.,  8.,  9., 14., 13., 12.,  5., 10.,  7., 12.,\n",
            "        12.,  7.,  7.,  8., 15.,  9.,  4.,  6.,  8., 11., 13., 21., 11., 14.,\n",
            "        10., 11., 14., 13., 12.,  9., 10.,  9., 14., 15.,  8., 10.,  6., 12.,\n",
            "        18., 10.,  5.,  9., 11., 10.,  7., 12.,  9., 10.,  7., 15., 15., 12.,\n",
            "        13., 10.,  8.,  7.,  7., 15.,  8.,  7.,  9., 14.,  9.,  7., 10.,  6.,\n",
            "         9., 12., 10., 17.,  6., 11., 14., 14., 10.,  7., 12., 10.,  4.,  8.,\n",
            "         9.,  8., 13., 11., 13., 14.,  9., 14.,  9.,  9.,  6., 13., 14.,  9.,\n",
            "         4.,  9.,  7., 16., 10.,  8., 16.,  9., 18., 10., 10.,  5., 17., 10.,\n",
            "        13., 12., 10., 11., 12., 12.,  8., 11., 10., 10., 10.,  7.,  7., 10.,\n",
            "         8., 11.,  7.,  8., 11.,  9.,  8., 13.,  5., 12.,  7.,  4.,  8., 13.,\n",
            "        15.,  5., 12.,  8.,  7., 11., 13.,  8., 12., 11., 12., 10., 13., 12.,\n",
            "         6.,  8., 12.,  8., 13.,  4., 11., 15.,  9., 10., 10.,  4., 12.,  8.,\n",
            "        10., 11.,  6., 12., 10.,  8., 15., 14., 13.,  8., 15., 10., 13., 13.,\n",
            "         5.,  8., 12., 10., 11., 12.,  8.,  2., 10.,  7.,  5., 10.,  9.,  9.,\n",
            "        12.,  6., 12.,  5.,  8., 14., 12., 13.,  8., 13., 10.,  4.,  9.,  9.,\n",
            "        12.,  6., 19.,  7., 10.,  8., 14., 12., 12., 14., 11.,  7., 12.,  8.,\n",
            "         7.,  6.,  8.,  5., 11., 13.,  6.,  9.,  9.,  8.,  8.,  6., 10., 11.,\n",
            "        12., 10., 12., 11., 14.,  7.,  8., 13.,  6., 10., 10.,  7.,  8., 13.,\n",
            "        10., 11., 12., 11., 15.,  4., 11.,  7., 11., 11., 11.,  3., 11., 11.,\n",
            "         7.,  5., 14., 12., 11., 13., 14.,  7.,  6.,  8.,  6.,  9., 12., 15.,\n",
            "        15., 12.,  8., 13., 12., 13.,  7.,  8.,  8., 15., 10., 10.,  6.,  7.,\n",
            "         5., 11., 13., 13.,  7.,  7.,  8., 11., 10., 14.,  3., 11., 11., 14.,\n",
            "        10.,  8.,  8., 11., 10., 14., 10.,  9.,  9.,  9.,  5., 13., 14., 16.,\n",
            "        14., 11.,  8.,  9.,  8.,  5., 17.,  8.,  5., 17.,  7., 18.,  7.,  9.,\n",
            "         7., 11., 12., 15.,  8., 11.,  6., 12., 10.,  8.,  8., 11., 11.,  8.,\n",
            "         6., 11., 11., 22.,  6.,  6., 10., 11.,  9., 11.,  9.,  9., 12.,  2.,\n",
            "         9., 11.,  8.,  5.,  6., 10., 12., 13., 10., 11.,  5.,  4.,  9.,  6.,\n",
            "        10., 15., 11.,  9.,  6., 11.,  9.,  9.,  7., 13.,  9.,  9.,  8.,  6.,\n",
            "         7.,  6., 12., 10., 10., 10.,  9., 12.,  8., 10.,  7.,  9., 16.,  9.,\n",
            "        13.,  7.,  7.,  8.,  7., 11., 16., 18., 19.,  6., 11., 11., 10., 11.,\n",
            "        11.,  9., 13., 11., 15.,  4.,  8., 10., 18.,  4., 10.,  9., 11., 12.,\n",
            "        10., 10.,  9.,  8., 11.,  8., 15., 12., 10.,  4., 12., 10., 13., 14.,\n",
            "        16.,  9.,  8., 10., 13., 18.,  6.,  8.,  7., 11.,  8.,  4.,  8., 10.,\n",
            "         4.,  9., 11.,  8., 11., 10.,  9.,  7.,  8., 17., 12.,  6., 11.,  6.,\n",
            "        10.,  9., 16., 10.,  9.,  9.,  3.,  9., 13., 12.,  6.,  8.,  9., 11.,\n",
            "        11.,  9., 13., 11., 10., 10., 19.,  7.,  6.,  7.,  7., 15., 11., 12.,\n",
            "         3.,  9., 12.,  6., 12., 10.,  7.,  8.,  5., 13.,  7., 10.,  9., 10.,\n",
            "         8.,  6.,  9.,  6., 13., 15., 18., 11.,  9.,  7., 14., 17., 10.,  4.,\n",
            "        16., 11., 13.,  8.,  9., 10., 10., 12.,  8., 15., 11., 10.,  9., 12.,\n",
            "        13.,  7., 15., 15.,  5., 12.,  9.,  6., 12.,  9., 12.,  9.,  7., 10.,\n",
            "        10., 16., 11.,  8.,  6.,  9.,  9.,  7.,  9.,  7.,  8.,  8.,  7., 11.,\n",
            "        12., 11., 11., 10., 10.,  8.,  7., 14., 11.,  6., 10.,  9.,  7., 15.,\n",
            "         7., 13., 10.,  7.,  9.,  8., 11.,  8., 17.,  9.,  8., 13.,  9.,  8.,\n",
            "         7., 11., 12.,  9.,  9.,  8., 13., 12., 10., 11.,  8., 13.,  1.,  5.,\n",
            "         5., 10.,  4., 13.,  6.,  8., 14., 12.,  9.,  9.,  5., 10., 15.,  5.,\n",
            "        10., 12.,  7.,  8.,  7., 10., 11.,  7.,  5.,  5.,  9., 12., 11.,  9.,\n",
            "        12.,  7.,  6.,  7., 21.,  7.,  8., 14., 11., 11., 10., 13., 15.,  8.,\n",
            "         9.,  6.,  9.,  7., 12.,  7.,  8.,  6., 12.,  6., 12.,  8., 10., 15.,\n",
            "         5., 12., 15.,  9.,  9.,  8., 13., 19., 14.,  6.,  9.,  7., 11.,  9.,\n",
            "        11.,  6., 12., 10.,  6., 13.,  9.,  5., 13.,  9., 13., 11., 14., 10.,\n",
            "        12., 10., 11., 15.,  5., 11.,  9., 11.,  7., 13., 15., 10., 10.,  7.,\n",
            "         7.,  7., 16., 13.,  9., 17., 17.,  7., 10., 12.,  6., 12.,  5.,  6.,\n",
            "        13.,  3.,  7., 12.,  9.,  5., 12., 10.,  6., 12.,  8., 10.,  8., 15.,\n",
            "         5., 10., 13.,  6.,  8., 14., 10., 11.,  9., 10.,  4.,  7., 13., 16.,\n",
            "        14.,  9., 12.,  4.,  9., 11.])\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Set number of samples\n",
        "num_samples = 1000\n",
        "\n",
        "# Define the two Poisson distributions\n",
        "pois_10 = dist.Poisson(10.0)\n",
        "pois_2 = dist.Poisson(2.0)\n",
        "\n",
        "# Flip a fair coin (Bernoulli) to decide which distribution to sample from\n",
        "bernoulli = dist.Bernoulli(0.5)\n",
        "choices = bernoulli.sample((num_samples,))\n",
        "\n",
        "# Sample from both distributions\n",
        "samples_10 = pois_10.sample((num_samples,))\n",
        "samples_2 = pois_2.sample((num_samples,))\n",
        "\n",
        "# Select samples based on choices\n",
        "samples = torch.where(choices.bool(), samples_10, samples_2)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(samples.numpy(), bins=20, density=True, alpha=0.7, color='lightblue', edgecolor='black')\n",
        "plt.title('Histogram of Samples from Poisson Mixture Model')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuGrVbCxKO4"
      },
      "source": [
        "## 4. MAP estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiVIWqsbxKO4"
      },
      "source": [
        "### Problem 4.1\n",
        "\n",
        "Let `data` be the samples from above. Assume there are $K = 2$ clusters and the prior cluster probabilities $[\\tfrac{1}{2}, \\tfrac{1}{2}]$ are known. Complete the code below to perform MAP estimation.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWbv_UWMxKO4"
      },
      "outputs": [],
      "source": [
        "def update_assignments(data, rates, probs):\n",
        "    \"\"\"Update the cluster assignments ($z$) given the data, rates,\n",
        "    and cluster probabilities.\n",
        "\n",
        "    Args:\n",
        "        data: shape `(N,)` tensor of counts\n",
        "        rates: shape `(K,)` tensor of nonnegative rates for each cluster.\n",
        "        probs: shape `(K,)` tensor of cluster probabilities\n",
        "\n",
        "    Returns:\n",
        "        assignments: shape `(N,)` tensor of integer cluster assignments\n",
        "    \"\"\"\n",
        "    ##\n",
        "    # YOUR CODE HERE\n",
        "    ##\n",
        "    return assignments\n",
        "\n",
        "def update_rates(data, assignments, shape=1.0, inv_scale=1.0):\n",
        "    \"\"\"Update the rates for each cluster under a gamma prior.\n",
        "\n",
        "    Args:\n",
        "        data: shape `(N,)` tensor of counts\n",
        "        assignments: shape `(N,)` tensor of integer cluster assignments\n",
        "        shape: shape (aka concentration) of gamma prior. Defaults to 1.0.\n",
        "        inv_scale: inverse scale (aka rate) of gamma prior. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        rates: shape `(K,)` tensor of updated rates for each cluster\n",
        "    \"\"\"\n",
        "    ##\n",
        "    # YOUR CODE HERE\n",
        "    ##\n",
        "    return rates\n",
        "\n",
        "\n",
        "def log_joint(data, assignments, rates, probs, shape=1.0, inv_scale=1.0):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        data: shape `(N,)` tensor of counts\n",
        "        assignments: shape `(N,)` tensor of integer cluster assignments\n",
        "        rates: shape `(K,)` tensor of updated rates for each cluster\n",
        "        probs: shape `(K,)` tensor of cluster probabilities\n",
        "        shape: shape (aka concentration) of gamma prior. Defaults to 1.0.\n",
        "        inv_scale: inverse scale (aka rate) of gamma prior. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        lp: scalar log joint probability under the mixture model\n",
        "    \"\"\"\n",
        "    ###\n",
        "    # YOUR CODE HERE\n",
        "    ##\n",
        "    return lp\n",
        "\n",
        "# Run coordinate ascent for some number of iterations, starting\n",
        "# with random cluster assignments\n",
        "probs = torch.ones(2) / 2.0\n",
        "assignments = torch.randint(0, 2, data.shape)\n",
        "rates = 10 * torch.rand(2)\n",
        "\n",
        "lps = []\n",
        "for i in range(20):\n",
        "    lps.append(log_joint(data, assignments, rates, probs))\n",
        "    rates = update_rates(data, assignments)\n",
        "    assignments = update_assignments(data, rates, probs)\n",
        "\n",
        "plt.plot(lps)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"log joint probability\")\n",
        "\n",
        "print(\"estimated rates:\", rates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTLnP-M0xKO4"
      },
      "source": [
        "### Problem 4.2 (Bonus)\n",
        "\n",
        "Now consider a more general model in which\n",
        "\n",
        "$$\n",
        "z_n \\sim \\mathrm{Cat}(\\boldsymbol{\\pi})\n",
        "$$\n",
        "\n",
        "where the prior cluster probabilities $\\boldsymbol{\\pi}$ are unknown. (Above, we assumed they were known to be $\\boldsymbol{\\pi} = [\\tfrac{1}{2}, \\tfrac{1}{2}]$.) Derive and implement a coordinate ascent algorithm for MAP estimation of $\\mathbf{z}_{\\mathsf{MAP}}$, $\\boldsymbol{\\lambda}_{\\mathsf{MAP}}$, and $\\boldsymbol{\\pi}_{\\mathsf{MAP}}$.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5b28c5bd4ee93d765ebe901023d5522822fb8ad083dac3187c5545022f913719"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}